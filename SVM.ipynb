{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nenorden/Transfer-learning-on-Fashion-MNIST/blob/master/SVM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "du6qu80fpl6C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Fashion-MNIST"
      ]
    },
    {
      "metadata": {
        "id": "U5tsOuhzqGKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5eee44ea-348e-4b97-afa9-06756f717a4c"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/zalandoresearch/fashion-mnist.git \n",
        "os.chdir('/content/fashion-mnist/')\n",
        "import utils.mnist_reader as mnist_reader\n",
        "os.chdir(\"/\")\n",
        "train_x_orig, train_y = mnist_reader.load_mnist('content/fashion-mnist/data/fashion', kind='train')\n",
        "test_x_orig, test_y = mnist_reader.load_mnist('content/fashion-mnist/data/fashion', kind='t10k')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'fashion-mnist' already exists and is not an empty directory.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K477rMNaoY0c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import ResNet Features"
      ]
    },
    {
      "metadata": {
        "id": "-96k9V53hIZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download features from Drive to virtual machine"
      ]
    },
    {
      "metadata": {
        "id": "Kb_APrWbogR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dcf06622-c862-4a7b-da4e-71671d727a7c"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "train_file_id = '1j1488T_da1oVlwwy-_19GMuY9tSucqzg'\n",
        "test_file_id = '1qR7fOsQ6TTW8eV8SnKN-jVvswlzMx9QM'\n",
        "\n",
        "os.chdir('/content/')\n",
        "# Load files by ID\n",
        "downloaded = drive.CreateFile({'id': train_file_id})\n",
        "downloaded.GetContentFile('train_fashion-MNIST_resnet.npy')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': test_file_id})\n",
        "downloaded.GetContentFile('test_fashion-MNIST_resnet.npy')\n",
        "\n",
        "# Files should be in /content/. Check!\n",
        "\n",
        "!ls\n",
        "os.chdir('/')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab        test_fashion-MNIST_resnet.npy\r\n",
            "fashion-mnist  train_fashion-MNIST_resnet.npy\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rc0_j5ilhMaX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load ResNet data"
      ]
    },
    {
      "metadata": {
        "id": "bt8XQJI6oL1w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.chdir('/content/')\n",
        "train_x = np.load('train_fashion-MNIST_resnet.npy')\n",
        "test_x = np.load('test_fashion-MNIST_resnet.npy')\n",
        "os.chdir('/')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9fwellc20pL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ]
    },
    {
      "metadata": {
        "id": "JmR_dOD9iUWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ResNet features"
      ]
    },
    {
      "metadata": {
        "id": "Btg1cL3r2UuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ed58a8c6-fad1-4c36-9e2f-3a26dd82127a"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "\n",
        "# Hyperparameters\n",
        "# C penalty parameter of error term. Smaller values -> stronger regularization.\n",
        "param_grid = {'C': [1e-1, 1e0], 'max_iter': [500, 1000]}\n",
        "\n",
        "# Create model and fit to training data. \n",
        "# Do grid search CV to find the best hyperparameters\n",
        "start_time = time.time()\n",
        "svm = svm.LinearSVC() # linear support vector classifier\n",
        "#svm = GridSearchCV(svm, param_grid)\n",
        "svm.fit(train_x, train_y)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# Print model with chosen hyperparameters\n",
        "print(svm)\n",
        "\n",
        "# Predict on test data\n",
        "svm_predict = svm.predict(test_x)\n",
        "\n",
        "# Get accuracy\n",
        "svm_acc = (svm_predict == test_y).mean()\n",
        "print(svm_acc)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 1135.4124119281769 seconds ---\n",
            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n",
            "0.7702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5eHHDSciZZM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Original features"
      ]
    },
    {
      "metadata": {
        "id": "49C6-VZaoOI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "4a462984-fee4-434e-a4cf-7ff7bc6ed7a0"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "\n",
        "# Hyper parameters\n",
        "# C penalty parameter of error term. Smaller values -> stronger regularization.\n",
        "param_grid = {'C': [1e-1, 1e0], 'max_iter': [500, 1000]}\n",
        "\n",
        "# Create model and fit to training data. \n",
        "# Do grid search CV to find the best hyperparameters\n",
        "start_time = time.time()\n",
        "svm_orig = svm.LinearSVC()\n",
        "svm_orig = GridSearchCV(svm_orig, param_grid)\n",
        "svm_orig.fit(train_x_orig, train_y)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# Print model with chosen hyperparameters\n",
        "print(svm_orig)\n",
        "\n",
        "# Predict on test data\n",
        "svm_predict_orig = svm_orig.predict(test_x_orig)\n",
        "\n",
        "# Get accuracy\n",
        "svm_acc_orig = (svm_predict_orig == test_y).mean()\n",
        "print(svm_acc_orig)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 2601.9068768024445 seconds ---\n",
            "GridSearchCV(cv=None, error_score='raise',\n",
            "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0),\n",
            "       fit_params=None, iid=True, n_jobs=1,\n",
            "       param_grid={'C': [0.1, 1.0], 'max_iter': [500, 1000]},\n",
            "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
            "       scoring=None, verbose=0)\n",
            "0.7687\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}